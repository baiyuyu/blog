---
layout: post
title: 二分类的评价指标
subtitle:  知识梳理
date: 2020-07-13
published: True
mathjax: True
catalog: true
tags:
  - 机器学习
  - 知识梳理
---
# TOC
1. 简介
{:toc}

# 简介
本篇主要是梳理在二分类中用到的各类指标、便于理解

*********************
* 前言：
之前在金融领域中一直在做类别不平衡的二分类问题，用的指标一直是auc、ks。因为是传统
用法，也一直有点不求甚解。最近涉及到一些别的指标，所有回顾一下二分类问题常用的评价指标便于理解。
*********************


# 二分类问题常用指标
二分类，只有两种标签，0或1。预测值也只有两种情况。根据以上，最直观的判断是混淆矩阵，如下：

## 混淆矩阵

<img src='/img/ML/confusion_matrix' width="600">

很多指标的计算都和次矩阵有关，其中TRUE、FALSE表示预测正确和错误 POSITIVE、NEIGTIVE
代表正样本和负样本

so，

true positive-TP：预测为1，预测正确即实际1

false positive-FP：预测为1，预测错误即实际0

true negative-TN：预测为0，预测正确即实际0

false negative-FN：预测为0，预测错误即实际1

【注】F开头的是预测错误的，如FP，预测错误的正样本，那么实际是负样本

## 精确率 召回率 准确率

是根据混淆矩阵衍生出来的最简单的一些指标
精确率：总体多少是预测准确的

$(TP+TN)/all$

准确率(查准率)precison：查的准吗？预测为正，是正的概率有多少？   预测为正正确的/总的预测为正的 对正样本来说

$precision= TP/（TP+FP）$

召回率 recall:查的全吗？正的里面有多少被预测为正了

$recall= TP/（TP+FN）$

实际的二分类中，更关注的是少类的表现，
positive-1标签可以代表健康也可以代表生病，但一般作为positive-1的指标指的是你更关注的样本表现，
比如“是垃圾邮件”“是阳性肿瘤”“将要发生地震”。

因此在肿瘤判断和地震预测等场景：

希望的是所有的地震都可以被预测到，正样本中查的全一些，recall高
要求模型有更高的【召回率】recall，是个地震你就都得给我揪出来不能放过

在垃圾邮件判断等场景：

希望判断为垃圾的都是真的垃圾，预测为正的是正的概率更高
要求模型有更高的【精确率】precision，你给我放进回收站里的可都得确定是垃圾，千万不能有正常邮件啊

理解：
我们可以把precision也理解为，当你的模型作出一个新的预测时，它的confidence score 是多少，或者它做的这个预测是对的的可能性是多少。
一般来说呢，鱼与熊掌不可兼得。如果你的模型很贪婪，想要覆盖更多的sample，那么它就更有可能犯错。在这种情况下，你会有很高的recall，
但是较低的precision。如果你的模型很保守，只对它很sure的sample作出预测，那么你的precision会很高，但是recall会相对低。
这样一来呢，我们可以选择只看我们感兴趣的class，就是minority class的precision，recall来评价模型的好坏。
画圈大一点的话，正样本更可能都被圈进来，但负样本也会圈进来，准确率变低，召回变大。

## f_SCORE
F1函数是一个常用指标，F1值是精确率和召回率的调和均值，即

$2*precision*recall / (precision + recall)$

## AUC
roc曲线下方的面积
roc曲线横纵轴：真正率和假正率
真正率即recall：所有真的正样本中的预测为正的样本 TP/(TP+FN)
假正率：所有负样本中预测为正的概率             FP/(TN+FP)
好的分类器，当假正率一定的情况下，真正率越高越好，即左上角更好
当x=y是，正样本中预测为正的概率和负样本中预测为正的概率相等，即随机，
我们希望正样本中预测为正的概率更高，所有auc越高越好

AUC的优势：AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价

AUC的其他解释：取不同分类阈值情况下的俩值，如果阈值为0，即没有预测为正的样本，都是0
如果阈值为1，则预测值都是正样本，都是1（画法）

解释2：根据预测值排序后，正样本的预测值大于负样本的预测值的概率。

## KS值
横轴变为阈值，
纵轴画真正率和假正率两条曲线，两条线之间差值。越大越好。
代表某个阈值的情况下，正样本预测为正的概率比负样本预测为正的概率大多数，越大越好。





